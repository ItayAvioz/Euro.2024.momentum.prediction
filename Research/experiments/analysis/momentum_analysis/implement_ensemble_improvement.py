#!/usr/bin/env python3
"""
Implement Ensemble Methods for Momentum Prediction Improvement
Practical demonstration of the highest priority improvement strategy
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.svm import SVR, SVC
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
import os
import warnings
warnings.filterwarnings('ignore')

class EnsembleModelImprovement:
    """Implement ensemble methods to improve momentum prediction"""
    
    def __init__(self):
        self.events_df = None
        self.momentum_data = None
        self.scaler = StandardScaler()
        
        # Individual models
        self.rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
        self.gb_reg = GradientBoostingRegressor(n_estimators=100, random_state=42)
        self.nn_reg = MLPRegressor(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000)
        
        self.rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
        self.gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)
        self.nn_clf = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000)
        
        # Ensemble models
        self.ensemble_reg = None
        self.ensemble_clf = None
        
    def load_data(self):
        """Load and prepare data"""
        print("üìä Loading Euro 2024 Dataset...")
        
        data_dir = "../Data"
        
        try:
            self.events_df = pd.read_csv(os.path.join(data_dir, "events_complete.csv"))
            print(f"‚úÖ Events: {len(self.events_df):,}")
            return True
        except FileNotFoundError as e:
            print(f"‚ùå Error: {e}")
            return False
    
    def create_enhanced_features(self, sample_size=8000):
        """Create enhanced features for better prediction"""
        print(f"\nüîß Creating Enhanced Features...")
        
        # Sample events strategically
        unique_matches = self.events_df['match_id'].unique()
        sampled_events = []
        
        events_per_match = max(1, sample_size // len(unique_matches))
        
        for match_id in unique_matches:
            match_events = self.events_df[self.events_df['match_id'] == match_id]
            if len(match_events) > events_per_match:
                match_sample = match_events.sample(n=events_per_match, random_state=42)
            else:
                match_sample = match_events
            sampled_events.append(match_sample)
        
        sampled_events = pd.concat(sampled_events, ignore_index=True)
        
        momentum_records = []
        processed_windows = 0
        
        # Process each match
        for match_id in sampled_events['match_id'].unique():
            match_events = sampled_events[sampled_events['match_id'] == match_id].copy()
            match_events = match_events.sort_values('minute')
            
            teams = match_events['team'].unique()
            
            for team in teams:
                max_minute = int(match_events['minute'].max())
                
                # Process in 3-minute windows
                for minute in range(6, max_minute + 1, 3):
                    # Current window (for features)
                    current_start = minute - 3
                    current_end = minute
                    
                    # Future window (for target)
                    future_start = minute
                    future_end = minute + 3
                    
                    current_window = match_events[
                        (match_events['minute'] >= current_start) & 
                        (match_events['minute'] < current_end)
                    ]
                    
                    future_window = match_events[
                        (match_events['minute'] >= future_start) & 
                        (match_events['minute'] < future_end)
                    ]
                    
                    team_current = current_window[current_window['team'] == team]
                    opponent_current = current_window[current_window['team'] != team]
                    team_future = future_window[future_window['team'] == team]
                    opponent_future = future_window[future_window['team'] != team]
                    
                    if len(team_current) == 0:
                        continue
                    
                    # Calculate enhanced features
                    features = self.calculate_enhanced_features(
                        team_current, opponent_current, current_window, match_events, minute
                    )
                    
                    # Calculate target
                    future_momentum = self.calculate_future_momentum(
                        team_future, opponent_future, future_window
                    )
                    
                    record = {
                        'match_id': match_id,
                        'team': team,
                        'minute': minute,
                        'future_momentum': future_momentum,
                        **features
                    }
                    
                    momentum_records.append(record)
                    processed_windows += 1
                    
                    if processed_windows % 500 == 0:
                        print(f"   Processed {processed_windows:,} windows...")
        
        self.momentum_data = pd.DataFrame(momentum_records)
        print(f"‚úÖ Created {len(self.momentum_data):,} enhanced samples")
        
        return self.momentum_data
    
    def calculate_enhanced_features(self, team_events, opponent_events, current_window, match_events, minute):
        """Calculate enhanced features for better prediction"""
        
        # Basic event counts
        total_events = len(team_events)
        opponent_events_count = len(opponent_events)
        
        # Event type analysis
        shot_events = len(team_events[team_events['type'].str.contains('Shot', na=False)])
        pass_events = len(team_events[team_events['type'].str.contains('Pass', na=False)])
        carry_events = len(team_events[team_events['type'].str.contains('Carry', na=False)])
        dribble_events = len(team_events[team_events['type'].str.contains('Dribble', na=False)])
        
        # Advanced metrics
        attacking_actions = shot_events + carry_events + dribble_events
        possession_pct = (total_events / (total_events + opponent_events_count + 1)) * 100
        events_per_minute = total_events / 3.0
        
        # Enhanced features
        # 1. Temporal features
        recent_events = len(team_events[team_events['minute'] >= minute - 1])  # Last minute
        momentum_trend = recent_events / (total_events / 3.0 + 1)  # Recent vs average
        
        # 2. Opponent-relative features
        activity_ratio = total_events / (opponent_events_count + 1)
        shot_advantage = shot_events - len(opponent_events[opponent_events['type'].str.contains('Shot', na=False)])
        
        # 3. Context features
        match_time_factor = minute / 90.0  # Game progression
        intensity_factor = (total_events + opponent_events_count) / 6.0  # Total activity
        
        # 4. Quality features
        pass_accuracy = pass_events / (total_events + 1)  # Pass ratio
        attacking_efficiency = attacking_actions / (total_events + 1)  # Attack efficiency
        
        # 5. Pressure features
        pressure_applied = len(team_events[team_events['type'].str.contains('Pressure', na=False)])
        pressure_received = len(opponent_events[opponent_events['type'].str.contains('Pressure', na=False)])
        pressure_balance = pressure_applied - pressure_received
        
        # 6. Historical momentum (previous windows)
        historical_momentum = self.calculate_historical_momentum(match_events, team_events.iloc[0]['team'] if len(team_events) > 0 else None, minute)
        
        # Current momentum calculation
        current_momentum = (
            shot_events * 2.0 +
            attacking_actions * 1.2 +
            (possession_pct - 50) * 0.05 +
            events_per_minute * 0.4 +
            pressure_balance * 0.3 +
            momentum_trend * 0.8
        )
        current_momentum = max(0, min(10, current_momentum))
        
        return {
            'total_events': total_events,
            'shot_events': shot_events,
            'pass_events': pass_events,
            'carry_events': carry_events,
            'dribble_events': dribble_events,
            'attacking_actions': attacking_actions,
            'possession_pct': possession_pct,
            'events_per_minute': events_per_minute,
            'recent_events': recent_events,
            'momentum_trend': momentum_trend,
            'activity_ratio': activity_ratio,
            'shot_advantage': shot_advantage,
            'match_time_factor': match_time_factor,
            'intensity_factor': intensity_factor,
            'pass_accuracy': pass_accuracy,
            'attacking_efficiency': attacking_efficiency,
            'pressure_applied': pressure_applied,
            'pressure_received': pressure_received,
            'pressure_balance': pressure_balance,
            'historical_momentum': historical_momentum,
            'current_momentum': current_momentum
        }
    
    def calculate_historical_momentum(self, match_events, team, minute):
        """Calculate historical momentum for context"""
        if team is None or minute <= 6:
            return 5.0
        
        # Look at previous 6 minutes
        historical_window = match_events[
            (match_events['minute'] >= minute - 6) & 
            (match_events['minute'] < minute - 3) &
            (match_events['team'] == team)
        ]
        
        if len(historical_window) == 0:
            return 5.0
        
        # Simple historical momentum
        shots = len(historical_window[historical_window['type'].str.contains('Shot', na=False)])
        attacks = len(historical_window[historical_window['type'].str.contains('Carry|Dribble', na=False)])
        
        return min(10, max(0, 5 + shots * 0.8 + attacks * 0.4))
    
    def calculate_future_momentum(self, team_future, opponent_future, future_window):
        """Calculate future momentum target"""
        if len(team_future) == 0:
            return 5.0
        
        # Use same calculation as current momentum
        total_events = len(team_future)
        opponent_events_count = len(opponent_future)
        
        shot_events = len(team_future[team_future['type'].str.contains('Shot', na=False)])
        attacking_actions = shot_events + len(team_future[team_future['type'].str.contains('Carry|Dribble', na=False)])
        possession_pct = (total_events / (total_events + opponent_events_count + 1)) * 100
        events_per_minute = total_events / 3.0
        
        future_momentum = (
            shot_events * 2.0 +
            attacking_actions * 1.2 +
            (possession_pct - 50) * 0.05 +
            events_per_minute * 0.4
        )
        
        return max(0, min(10, future_momentum))
    
    def build_ensemble_models(self):
        """Build ensemble models combining multiple algorithms"""
        print("\nü§ñ Building Ensemble Models...")
        
        # Create voting regressor
        self.ensemble_reg = VotingRegressor(
            estimators=[
                ('rf', self.rf_reg),
                ('gb', self.gb_reg),
                ('nn', self.nn_reg)
            ],
            weights=[0.4, 0.4, 0.2]  # RF and GB get more weight
        )
        
        # Create voting classifier
        self.ensemble_clf = VotingClassifier(
            estimators=[
                ('rf', self.rf_clf),
                ('gb', self.gb_clf),
                ('nn', self.nn_clf)
            ],
            voting='soft',
            weights=[0.4, 0.4, 0.2]
        )
        
        print("‚úÖ Ensemble models created")
    
    def convert_to_categories(self, momentum_scores):
        """Convert momentum scores to balanced categories"""
        categories = []
        for score in momentum_scores:
            if score < 0.90:
                categories.append('low')
            elif score < 3.94:
                categories.append('medium')
            else:
                categories.append('high')
        return np.array(categories)
    
    def train_and_evaluate(self):
        """Train and evaluate both individual and ensemble models"""
        print("\nüìä Training and Evaluating Models...")
        
        # Prepare features
        feature_cols = [
            'total_events', 'shot_events', 'attacking_actions', 'possession_pct',
            'events_per_minute', 'momentum_trend', 'activity_ratio', 'shot_advantage',
            'match_time_factor', 'intensity_factor', 'attacking_efficiency',
            'pressure_balance', 'historical_momentum', 'current_momentum'
        ]
        
        X = self.momentum_data[feature_cols]
        y_continuous = self.momentum_data['future_momentum']
        y_categorical = self.convert_to_categories(y_continuous)
        
        # Split data
        X_train, X_test, y_cont_train, y_cont_test = train_test_split(
            X, y_continuous, test_size=0.2, random_state=42
        )
        _, _, y_cat_train, y_cat_test = train_test_split(
            X, y_categorical, test_size=0.2, random_state=42
        )
        
        # Scale features for neural network
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        print(f"üìä Training samples: {len(X_train):,}")
        print(f"üìä Testing samples: {len(X_test):,}")
        print(f"üìä Features: {len(feature_cols)}")
        
        # Train individual models
        print("\nüîß Training Individual Models...")
        
        # Regression models
        self.rf_reg.fit(X_train, y_cont_train)
        self.gb_reg.fit(X_train, y_cont_train)
        self.nn_reg.fit(X_train_scaled, y_cont_train)
        
        # Classification models
        self.rf_clf.fit(X_train, y_cat_train)
        self.gb_clf.fit(X_train, y_cat_train)
        self.nn_clf.fit(X_train_scaled, y_cat_train)
        
        # Train ensemble models
        print("üîß Training Ensemble Models...")
        
        # For ensemble, we need to prepare data differently for NN
        X_train_for_ensemble = X_train.copy()
        X_test_for_ensemble = X_test.copy()
        
        self.ensemble_reg.fit(X_train_for_ensemble, y_cont_train)
        self.ensemble_clf.fit(X_train_for_ensemble, y_cat_train)
        
        # Evaluate all models
        self.evaluate_all_models(X_test, X_test_scaled, y_cont_test, y_cat_test, feature_cols)
    
    def evaluate_all_models(self, X_test, X_test_scaled, y_cont_test, y_cat_test, feature_cols):
        """Evaluate all models and compare performance"""
        print("\nüìà MODEL PERFORMANCE COMPARISON")
        print("=" * 80)
        
        # Regression evaluation
        print("üî¢ REGRESSION MODELS (R¬≤ Score | MAE):")
        print("-" * 50)
        
        # Individual models
        rf_pred = self.rf_reg.predict(X_test)
        gb_pred = self.gb_reg.predict(X_test)
        nn_pred = self.nn_reg.predict(X_test_scaled)
        
        # Ensemble model
        ensemble_pred = self.ensemble_reg.predict(X_test)
        
        models_reg = {
            'Random Forest': rf_pred,
            'Gradient Boost': gb_pred,
            'Neural Network': nn_pred,
            'Ensemble': ensemble_pred
        }
        
        best_r2 = -999
        best_model_reg = None
        
        for name, predictions in models_reg.items():
            r2 = r2_score(y_cont_test, predictions)
            mae = mean_absolute_error(y_cont_test, predictions)
            
            if r2 > best_r2:
                best_r2 = r2
                best_model_reg = name
            
            print(f"   {name:<15}: R¬≤ {r2:>6.3f} | MAE {mae:>5.3f}")
        
        print(f"\nüèÜ Best Regression Model: {best_model_reg} (R¬≤ {best_r2:.3f})")
        
        # Classification evaluation
        print(f"\nüéØ CLASSIFICATION MODELS (Accuracy):")
        print("-" * 50)
        
        # Individual models
        rf_clf_pred = self.rf_clf.predict(X_test)
        gb_clf_pred = self.gb_clf.predict(X_test)
        nn_clf_pred = self.nn_clf.predict(X_test_scaled)
        
        # Ensemble model
        ensemble_clf_pred = self.ensemble_clf.predict(X_test)
        
        models_clf = {
            'Random Forest': rf_clf_pred,
            'Gradient Boost': gb_clf_pred,
            'Neural Network': nn_clf_pred,
            'Ensemble': ensemble_clf_pred
        }
        
        best_accuracy = 0
        best_model_clf = None
        
        for name, predictions in models_clf.items():
            accuracy = accuracy_score(y_cat_test, predictions)
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_model_clf = name
            
            print(f"   {name:<15}: Accuracy {accuracy:>6.3f} ({accuracy*100:.1f}%)")
        
        print(f"\nüèÜ Best Classification Model: {best_model_clf} (Accuracy {best_accuracy:.3f})")
        
        # Detailed ensemble analysis
        print(f"\nüîç DETAILED ENSEMBLE ANALYSIS:")
        print("-" * 50)
        
        # Cross-validation
        ensemble_cv_reg = cross_val_score(self.ensemble_reg, X_test, y_cont_test, cv=5)
        ensemble_cv_clf = cross_val_score(self.ensemble_clf, X_test, y_cat_test, cv=5)
        
        print(f"   Ensemble Regression CV: {ensemble_cv_reg.mean():.3f} ¬± {ensemble_cv_reg.std():.3f}")
        print(f"   Ensemble Classification CV: {ensemble_cv_clf.mean():.3f} ¬± {ensemble_cv_clf.std():.3f}")
        
        # Feature importance (from Random Forest component)
        print(f"\nüîç TOP 10 FEATURE IMPORTANCE:")
        feature_importance = list(zip(feature_cols, self.rf_reg.feature_importances_))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        for i, (feature, importance) in enumerate(feature_importance[:10], 1):
            print(f"   {i:2d}. {feature:<25}: {importance:.3f}")
        
        # Classification report for ensemble
        print(f"\nüìã ENSEMBLE CLASSIFICATION REPORT:")
        report = classification_report(y_cat_test, ensemble_clf_pred, output_dict=True)
        
        for category in ['low', 'medium', 'high']:
            if category in report:
                metrics = report[category]
                print(f"   {category.upper():<6}: Precision {metrics['precision']:.3f} | " +
                      f"Recall {metrics['recall']:.3f} | F1 {metrics['f1-score']:.3f}")
        
        # Improvement summary
        print(f"\nüìä IMPROVEMENT SUMMARY:")
        print("=" * 50)
        
        print(f"üîÑ BASELINE vs ENSEMBLE COMPARISON:")
        print(f"   Baseline R¬≤: -0.181 ‚Üí Ensemble R¬≤: {best_r2:.3f}")
        print(f"   Baseline Accuracy: 35.9% ‚Üí Ensemble Accuracy: {best_accuracy*100:.1f}%")
        
        improvement_r2 = best_r2 - (-0.181)
        improvement_acc = (best_accuracy * 100) - 35.9
        
        print(f"\nüéØ IMPROVEMENTS ACHIEVED:")
        print(f"   R¬≤ improvement: +{improvement_r2:.3f} ({improvement_r2/abs(-0.181)*100:.1f}% better)")
        print(f"   Accuracy improvement: +{improvement_acc:.1f}% ({improvement_acc/35.9*100:.1f}% better)")
        
        if best_r2 > 0.3:
            print(f"   ‚úÖ SIGNIFICANT IMPROVEMENT ACHIEVED!")
        else:
            print(f"   ‚ö†Ô∏è  Moderate improvement, further work needed")
    
    def provide_next_steps(self):
        """Provide recommendations for next steps"""
        print(f"\nüéØ NEXT STEPS FOR FURTHER IMPROVEMENT")
        print("=" * 60)
        
        print("üöÄ IMMEDIATE ACTIONS (Next 1-2 weeks):")
        print("   1. üîß Implement XGBoost and LightGBM")
        print("   2. üìä Add more contextual features")
        print("   3. üïê Implement LSTM for temporal modeling")
        print("   4. üéØ Fine-tune ensemble weights")
        
        print("\nüìà EXPECTED NEXT IMPROVEMENTS:")
        print("   ‚Ä¢ XGBoost: +0.05-0.10 R¬≤ improvement")
        print("   ‚Ä¢ Enhanced features: +0.10-0.15 R¬≤ improvement")
        print("   ‚Ä¢ LSTM temporal: +0.15-0.25 R¬≤ improvement")
        print("   ‚Ä¢ Combined target: R¬≤ > 0.50, Accuracy > 65%")
        
        print("\nüí° STRATEGIC RECOMMENDATIONS:")
        print("   ‚Ä¢ Focus on temporal patterns (LSTM)")
        print("   ‚Ä¢ Add player-specific features")
        print("   ‚Ä¢ Implement confidence scoring")
        print("   ‚Ä¢ Test on different prediction horizons")

def main():
    """Run the ensemble improvement implementation"""
    print("üöÄ ENSEMBLE METHODS IMPROVEMENT IMPLEMENTATION")
    print("=" * 80)
    
    ensemble = EnsembleModelImprovement()
    
    # Load data
    if not ensemble.load_data():
        print("‚ùå Failed to load data")
        return
    
    # Create enhanced features
    ensemble.create_enhanced_features()
    
    # Build ensemble models
    ensemble.build_ensemble_models()
    
    # Train and evaluate
    ensemble.train_and_evaluate()
    
    # Provide next steps
    ensemble.provide_next_steps()
    
    print("\n‚úÖ ENSEMBLE IMPROVEMENT IMPLEMENTATION COMPLETE")

if __name__ == "__main__":
    main() 